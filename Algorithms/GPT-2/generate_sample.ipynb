{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generate_sample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhOqnV4PNO1x"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--srh9QWNM8Q",
        "outputId": "e9a842bb-e06e-4251-866c-01899840ffae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYhcQ8ISOBH2",
        "outputId": "f6b04d22-3697-4051-878a-530e4f66f214"
      },
      "source": [
        "%cd /content/drive/MyDrive/Advocacy/finetuned/gpt-2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1dhHuEjx72woFBDqXv7grEh2o-cB3dhyO/Advocacy/finetuned/gpt-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM45hBViOEdp",
        "outputId": "9c6dd8b2-1d9a-40c0-d33d-3c1a9faa0cb5"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcheckpoint\u001b[0m/      Dockerfile.gpu     LICENSE        README.md         \u001b[01;34mtwremat\u001b[0m/\n",
            "CONTRIBUTORS.md  domains.txt        model_card.md  requirements.txt\n",
            "DEVELOPERS.md    download_model.py  \u001b[01;34mmodels\u001b[0m/        \u001b[01;34msrc\u001b[0m/\n",
            "Dockerfile.cpu   encode.py          output.log     train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1EsGC4GN1YJ",
        "outputId": "624665a7-5315-4c64-adc4-096d295f2eb9"
      },
      "source": [
        "# %cd /content/drive/MyDrive/thesis/models/zeenews/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/thesis/models/zeenews\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0gSICnjOKl6",
        "outputId": "4aeff86f-4d53-4e3d-9147-7802641c8e52"
      },
      "source": [
        "# cd gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/thesis/models/zeenews/gpt-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHmeskamOUC3",
        "outputId": "68edc7e7-a31a-4f6c-c0ff-5550bf168488"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "  Downloading regex-2017.04.05.tar.gz (601 kB)\n",
            "\u001b[K     |████████████████████████████████| 601 kB 25.9 MB/s \n",
            "\u001b[?25hCollecting requests==2.21.0\n",
            "  Downloading requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "  Downloading tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting toposort==1.5\n",
            "  Downloading toposort-1.5-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Building wheels for collected packages: regex, fire\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp37-cp37m-linux_x86_64.whl size=534439 sha256=9eb1922849a14508d7fe95fdb15a1e7b435d1ef70e3be67ac9cfea1c393bd5ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/e8/a5/d4894e7ef29935f75c6074409ce8ca80a0271f0ce2a30da5d3\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=abebc116097607b007cfe2263c58c282dd151f4a31785bbe76fe044cb7490462\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built regex fire\n",
            "Installing collected packages: idna, tqdm, toposort, requests, regex, fire\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.0\n",
            "    Uninstalling tqdm-4.62.0:\n",
            "      Successfully uninstalled tqdm-4.62.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.21.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.31.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed fire-0.4.0 idna-2.8 regex-2017.4.5 requests-2.21.0 toposort-1.5 tqdm-4.31.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTtqKBO3Oz3o"
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrq-i_1xPKS5"
      },
      "source": [
        "!chmod 755 -R /content/drive/MyDrive/Advocacy/finetuned/gpt-2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQOPI05nRKQe"
      },
      "source": [
        "# !chmod 755 -R /content/drive/MyDrive/thesis/models/zeenews/gpt-2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkAdvig8q9jw",
        "outputId": "6e88148c-430d-4d0e-91f4-35418df123d7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VtUXLfT5FkT"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/Advocacy/finetuned/gpt-2/checkpoint/run2/* /content/drive/MyDrive/Advocacy/finetuned/gpt-2/models/774M/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTPUxWUxQJIy",
        "outputId": "778e27d4-7987-45d6-c64f-cde21ff49ca2"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py  --model_name '774M' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 5623, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 73, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 88, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1649, in __exit__\n",
            "    close_thread.start()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 857, in start\n",
            "    self._started.wait()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 552, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "NQ3Qf_dNgD1G",
        "outputId": "2caede14-c218-4889-9a04-dd120eaba312"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "Dir_path = '/content/drive/MyDrive/thesis/dataset/articleTxt/test_final/zeenews/'\n",
        "csv_file = '/content/drive/MyDrive/thesis/dataset/articleTxt/test_final/zeenews.csv'\n",
        "\n",
        "if (os.path.exists(csv_file)):\n",
        "  hcsvfile = open(csv_file, 'a', newline='') \n",
        "  writer = csv.writer(hcsvfile)    \n",
        "else:\n",
        "  hcsvfile = open(csv_file, 'w', newline='') \n",
        "  writer = csv.writer(hcsvfile)\n",
        "  writer.writerow([\"File_name\",\"Entity\", \"Trigger\", \"Output\", \"AdjectivePresent\", \"InputSentiment\", \"OutputSentiment\",])\n",
        "      \n",
        "files = os.listdir(Dir_path)\n",
        "dirsize = len(files)\n",
        "count = 0\n",
        "clus_all = []\n",
        "for file in files:\n",
        "  count = count + 1\n",
        "  if count>2:\n",
        "    break\n",
        "  \n",
        "  if -1 != file.find(\"done\"):\n",
        "    continue\n",
        "\n",
        "  print(str(count)+\"/\"+str(dirsize))\n",
        "  print(Dir_path+file)\n",
        "\n",
        "  f = open(Dir_path+file,'r')\n",
        "  data = json.load(f)\n",
        "  f.close()\n",
        "\n",
        "  d = data[\"PER\"]\n",
        "  #print(d)\n",
        "  \n",
        "  trigger = \" can be described as \"\n",
        "  for item in d:\n",
        "\n",
        "    compSent = item['sent'].strip()\n",
        "    entity_name = item[\"entity_name\"]\n",
        "    if compSent[-1] !='.':\n",
        "      compSent +='.'\n",
        "    input = compSent+ \" \" +entity_name + trigger\n",
        "    #print(input)\n",
        "\n",
        "    out_text = compSent\n",
        "    #get first two sentences\n",
        "    sent_list = sent_tokenize(out_text)\n",
        "    sent_list_len = len(sent_list)\n",
        "    if(sent_list_len > 0):\n",
        "      iterCount = 0\n",
        "      out_text = \"\"\n",
        "      while(out_text == \"\" and iterCount < sent_list_len): \n",
        "          out_text = sent_list[iterCount]\n",
        "          iterCount+=1\n",
        "      if(out_text[0]>=\"\\u0900\" and out_text[0] < \"\\u097F\"):\n",
        "        print(\"hindi text found\")\n",
        "          \n",
        "    #print(entity_name + trigger + out_text)\n",
        "    if(out_text != \"\"):\n",
        "      writer.writerow([file,entity_name, trigger , out_text,\"\",\"\",\"\"])\n",
        "  new_filename = file.replace('_list.json','_list_done.json')\n",
        "  os.rename(Dir_path+file,Dir_path+new_filename) \n",
        "hcsvfile.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-aa84911de8f7>\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    elif(re = out_text.find(\"#\")):\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mpRS8hywqe3"
      },
      "source": [
        "undo done rename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "47nXw5TwwqBy",
        "outputId": "0b872993-17cb-4c8c-b6b8-4ef563230f52"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "Dir_path = '/content/drive/MyDrive/thesis/dataset/articleTxt/test_final/zeenews/'\n",
        "\n",
        "files = os.listdir(Dir_path)\n",
        "dirsize = len(files)\n",
        "#print(str(dirsize))\n",
        "count = 0\n",
        "clus_all = []\n",
        "for file in files:\n",
        "  count = count + 1\n",
        "  #if count>2:\n",
        "    #break\n",
        "  \n",
        "  if -1 == file.find(\"done\"):\n",
        "    continue\n",
        "\n",
        "  print(str(count)+\"/\"+str(dirsize))\n",
        "  print(Dir_path+file)\n",
        "  new_filename = file.replace('_list_done.json','_list.json')\n",
        "  os.rename(Dir_path+file,Dir_path+new_filename) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2a4357c5d1d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/thesis/dataset/articleTxt/test_final/zeenews/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdirsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(str(dirsize))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/thesis/dataset/articleTxt/test_final/zeenews/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxq0LDRHUMSD",
        "outputId": "e390e856-f0f8-4a1e-97dc-46e89bbce968"
      },
      "source": [
        "cd src/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1dhHuEjx72woFBDqXv7grEh2o-cB3dhyO/Advocacy/finetuned/gpt-2/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxsF2u1GoYR6",
        "outputId": "9a889513-0186-4cd6-92a7-3b6d194f41ad"
      },
      "source": [
        "data = \"\"\n",
        "with open('../../../all_tweets_test/test_Election2019_tweets.csv', \"r\") as f:\n",
        "  a = f.readline()\n",
        "  while a:\n",
        "    data+=\" \"+a.strip()\n",
        "    a = f.readline()\n",
        "data = list(filter(lambda x : len(x)>0, data.split(\"<|endoftext|>\")))\n",
        "data "
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' RT @MinhazMerchant: #MFN status to Pak revoked. Finally, 23 years after granting MFN to Pak without reciprocity, it has taken dozens of ter…',\n",
              " 'AIADMK, BJP to lead a front in TN #AIADMK #BJP #TamilNadu #LokSabhaElection2019 #LokSabhaElections2019 #DMDK #Vijayakanth #PattaliMakkalKatchi #SRamadas #PuthiyaTamizhagam #Krishnaswamy #PiyushGoyal #PThangamani #SPVelumani https://t.co/yeey7Du3F5',\n",
              " 'RT @Rajeev17109032: THE BITTER TRUTH WHICH INDIANS MUST QUICKLY ACCEPT! #pulwamaattack #Pulwama #PulwamaTerrorAttack #StandWithForces #Phul…']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vfNGYzP-xVK",
        "outputId": "9f9ee001-65c3-405d-86ee-c5a52ad8922e"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import fire\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "#nishchay\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "\n",
        "import model, sample, encoder\n",
        "\n",
        "def interact_model(\n",
        "    model_name='774M',\n",
        "    seed=100,\n",
        "    nsamples=3,\n",
        "    batch_size=1,\n",
        "    length=20,\n",
        "    temperature=1,\n",
        "    top_k=0,\n",
        "    top_p=1,\n",
        "    models_dir='../models',\n",
        "):\n",
        "    \"\"\"\n",
        "    Interactively run the model\n",
        "    :model_name=124M : String, which model to use\n",
        "    :seed=None : Integer seed for random number generators, fix seed to reproduce\n",
        "     results\n",
        "    :nsamples=1 : Number of samples to return total\n",
        "    :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples.\n",
        "    :length=None : Number of tokens in generated text, if None (default), is\n",
        "     determined by model hyperparameters\n",
        "    :temperature=1 : Float value controlling randomness in boltzmann\n",
        "     distribution. Lower temperature results in less random completions. As the\n",
        "     temperature approaches zero, the model will become deterministic and\n",
        "     repetitive. Higher temperature results in more random completions.\n",
        "    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n",
        "     considered for each step (token), resulting in deterministic completions,\n",
        "     while 40 means 40 words are considered at each step. 0 (default) is a\n",
        "     special setting meaning no restrictions. 40 generally is a good value.\n",
        "     :models_dir : path to parent folder containing model subfolders\n",
        "     (i.e. contains the <model_name> folder)\n",
        "    \"\"\"\n",
        "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "    assert nsamples % batch_size == 0\n",
        "\n",
        "    enc = encoder.get_encoder(model_name, models_dir)\n",
        "    hparams = model.default_hparams()\n",
        "    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "        hparams.override_from_dict(json.load(f))\n",
        "\n",
        "    if length is None:\n",
        "        length = hparams.n_ctx // 2\n",
        "    elif length > hparams.n_ctx:\n",
        "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "        np.random.seed(seed)\n",
        "        tf.set_random_seed(seed)\n",
        "        output = sample.sample_sequence(\n",
        "            hparams=hparams, length=length,\n",
        "            context=context,\n",
        "            batch_size=batch_size,\n",
        "            temperature=temperature, top_k=top_k, top_p=top_p\n",
        "        )\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "        saver.restore(sess, ckpt)\n",
        "        \n",
        "        #nishchay\n",
        "        # csv_file = '/content/drive/MyDrive/Advocacy//test_final/timesofindia_manual.csv'\n",
        "\n",
        "        # if (os.path.exists(csv_file)):\n",
        "        #     hcsvfile = open(csv_file, 'a', newline='') \n",
        "        #     writer = csv.writer(hcsvfile)    \n",
        "        # else:\n",
        "        #     hcsvfile = open(csv_file, 'w', newline='') \n",
        "        #     writer = csv.writer(hcsvfile)\n",
        "        #     writer.writerow([\"index\",\"Sample\", \"Entity\", \"trigger\", \"output\",\"failcount\" \"AdjectivePresent\", \"inputSentiment\", \"outputSentiment\",])\n",
        "              \n",
        "        count = 0\n",
        "        triger_list =[\n",
        "                # \"Q: Is it true that preceding sentence advocates a cause? A: \",\n",
        "                # \"Q: Is it true that preceding sentence hyper-advocates a cause ? A: \",\n",
        "                # \"Q: Is it true that preceding sentence is a disinformation ? A: \",\n",
        "                # \"Q: Is it true that preceding sentence is a about a propaganda ? A: \",\n",
        "                # \"Q: Is it true that preceding sentence favors a cause ? A: \",\n",
        "                # \"Q: Is it true that preceding sentence is against a cause? A: \",\n",
        "                # \"Q: Is it true or false that the preceding statement is an advocate? A: \"\n",
        "                \"Q: The preceding statement is advocating a cause. True or False? A: \"\n",
        "                ]\n",
        "        # entity_list = [\"Narendra Modi \",\n",
        "        #         \"Rahul Gandhi \",\n",
        "        #         \"Nitish Kumar \",\n",
        "        #         \"Mamata Banerjee \",\n",
        "        #         \"Sonia Gandhi \",\n",
        "        #         \"Amit Shah \",\n",
        "        #         \"Lalu Prasad \",\n",
        "        #         \"Mayawati \",\n",
        "        #         \"Manmohan Singh \",\n",
        "        #         \"Arvind Kejriwal \",\n",
        "        #         \"Yogi Adityanath \"\n",
        "        #         ]\n",
        "        # for entity_name in entity_list:\n",
        "        #     count = count + 1\n",
        "        #     #if count>100:\n",
        "        #         #break\n",
        "        #     print(str(count)+\"/\"+str(len(entity_list)))\n",
        "\n",
        "        for line in data:\n",
        "          for trigger in triger_list:\n",
        "              fail_count = 0\n",
        "              raw_text = line + \". \" + trigger\n",
        "              out_text = \"\"\n",
        "              if not raw_text:\n",
        "                  continue\n",
        "              context_tokens = enc.encode(raw_text)\n",
        "              generated = 0\n",
        "              ki = 0\n",
        "              while ki < (nsamples // batch_size):\n",
        "                  ki+=1\n",
        "                  out = sess.run(output, feed_dict={\n",
        "                      context: [context_tokens for _ in range(batch_size)]\n",
        "                  })[:, len(context_tokens):]\n",
        "                  for i in range(batch_size):\n",
        "                      generated += 1\n",
        "                      out_text = enc.decode(out[i])\n",
        "                      sent_list = sent_tokenize(out_text)\n",
        "                      sent_list_len = len(sent_list)\n",
        "                      #print(\"sentence count \" +str(sent_list_len))\n",
        "                      out_text = \"\"\n",
        "                      if(sent_list_len > 0):\n",
        "                          iterCount = 0\n",
        "                          while(out_text == \"\" and iterCount < sent_list_len): \n",
        "                              out_text = sent_list[iterCount]\n",
        "                              #print(\"itercount : \"+str(iterCount)+\" \"+ out_text)\n",
        "                              iterCount+=1\n",
        "                          out_text=out_text.strip()\n",
        "                          if(out_text != \"\"):\n",
        "                              #print(\"perm new line \" + str(out_text.find(\"\\n\")))\n",
        "                              if(-1 != out_text.find(\"\\n\",0,-1)):\n",
        "                                  #out_text = \"\"\n",
        "                                  ki -= 1\n",
        "                                  fail_count+=1\n",
        "                                  continue\n",
        "                                  #print(\"new line \" + str(out_text.find(\"\\n\",0,-1)))\n",
        "                              else:\n",
        "                                  \n",
        "                                  #punc = '''!''()-—[]{};:'\"\\, <>./?@#$%^&*_~``‘’“”'''\n",
        "                                  #punc = '''()''-—'\", .``‘’“”'''\n",
        "                                  if(False == bool(re.match(\"^[A-Za-z]+[\\sA-Za-z0-9\\-—()'\\\"&, .`?!%`‘’“”]*$\", out_text ))):\n",
        "                                    if fail_count < 100:\n",
        "                                      ki -= 1\n",
        "                                      fail_count+=1\n",
        "                                      continue\n",
        "                              # print(\"\\n\"+raw_text+out_text+\"\\n\")\n",
        "                      print(\"sample \"+str(ki)+\" : \"+raw_text+out_text)\n",
        "              print(\"=\"*80)\n",
        "          print(\"-_\"*80)                                \n",
        "                      # writer.writerow([count, ki, entity_name, trigger ,out_text,fail_count,\"\",\"\",\"\"])\n",
        "        # hcsvfile.close()\n",
        "        \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    fire.Fire(interact_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ../models/774M/model.ckpt\n",
            "sample 1 :  RT @MinhazMerchant: #MFN status to Pak revoked. Finally, 23 years after granting MFN to Pak without reciprocity, it has taken dozens of ter…. Q: The preceding statement is advocating a cause. True or False? A: May be.\n",
            "sample 2 :  RT @MinhazMerchant: #MFN status to Pak revoked. Finally, 23 years after granting MFN to Pak without reciprocity, it has taken dozens of ter…. Q: The preceding statement is advocating a cause. True or False? A: I…<|endoftext|>To all those liars who want to help to\n",
            "sample 3 :  RT @MinhazMerchant: #MFN status to Pak revoked. Finally, 23 years after granting MFN to Pak without reciprocity, it has taken dozens of ter…. Q: The preceding statement is advocating a cause. True or False? A: …<|endoftext|>RT @NairShilpa1308: Norwegian Parliament\n",
            "================================================================================\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
            "sample 1 : AIADMK, BJP to lead a front in TN #AIADMK #BJP #TamilNadu #LokSabhaElection2019 #LokSabhaElections2019 #DMDK #Vijayakanth #PattaliMakkalKatchi #SRamadas #PuthiyaTamizhagam #Krishnaswamy #PiyushGoyal #PThangamani #SPVelumani https://t.co/yeey7Du3F5. Q: The preceding statement is advocating a cause. True or False? A: Note that in these trains belong to Sonia Gandhi, who recently announced that she will take it up in\n",
            "sample 2 : AIADMK, BJP to lead a front in TN #AIADMK #BJP #TamilNadu #LokSabhaElection2019 #LokSabhaElections2019 #DMDK #Vijayakanth #PattaliMakkalKatchi #SRamadas #PuthiyaTamizhagam #Krishnaswamy #PiyushGoyal #PThangamani #SPVelumani https://t.co/yeey7Du3F5. Q: The preceding statement is advocating a cause. True or False? A: BJP's intentions still remain undeclared, but their stated phrases give an intimidating atmosphere\n",
            "sample 3 : AIADMK, BJP to lead a front in TN #AIADMK #BJP #TamilNadu #LokSabhaElection2019 #LokSabhaElections2019 #DMDK #Vijayakanth #PattaliMakkalKatchi #SRamadas #PuthiyaTamizhagam #Krishnaswamy #PiyushGoyal #PThangamani #SPVelumani https://t.co/yeey7Du3F5. Q: The preceding statement is advocating a cause. True or False? A: Most r minor in nature.\n",
            "================================================================================\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
            "sample 1 : RT @Rajeev17109032: THE BITTER TRUTH WHICH INDIANS MUST QUICKLY ACCEPT! #pulwamaattack #Pulwama #PulwamaTerrorAttack #StandWithForces #Phul…. Q: The preceding statement is advocating a cause. True or False? A: True.\n",
            "sample 2 : RT @Rajeev17109032: THE BITTER TRUTH WHICH INDIANS MUST QUICKLY ACCEPT! #pulwamaattack #Pulwama #PulwamaTerrorAttack #StandWithForces #Phul…. Q: The preceding statement is advocating a cause. True or False? A: YES!\n",
            "sample 3 : RT @Rajeev17109032: THE BITTER TRUTH WHICH INDIANS MUST QUICKLY ACCEPT! #pulwamaattack #Pulwama #PulwamaTerrorAttack #StandWithForces #Phul…. Q: The preceding statement is advocating a cause. True or False? A: Really?\n",
            "================================================================================\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[31mERROR: \u001b[0mCould not consume arg: -f\n",
            "Usage: ipykernel_launcher.py -\n",
            "\n",
            "For detailed information on this command, run:\n",
            "  ipykernel_launcher.py - --help\n"
          ]
        },
        {
          "ename": "FireExit",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mFireExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1fArraQgE_w",
        "outputId": "1a79a2f7-b048-493f-b367-406e5602caf7"
      },
      "source": [
        "out_text = \"h??\"\n",
        "print(bool(re.match(\"^[A-Za-z]+[\\sA-Za-z0-9\\-—()'\\\"&, .`?!%`‘’“”]*$\", out_text )))\n",
        "                                    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IX6LqklSolNO",
        "outputId": "c0b5761e-3779-41e8-e3c4-c699ffb2cf73"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1dhHuEjx72woFBDqXv7grEh2o-cB3dhyO/Advocacy/finetuned/gpt-2/src'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvTNCKQGO8q7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}